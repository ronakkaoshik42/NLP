{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.txt\", \"r\")\n",
    "#f = open(\"test.txt\", \"r\")\n",
    "l=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['meta\\t8\\tneutral\\n', 'RT\\tEng\\n', '@\\tO\\n', 'UAAPconfessions\\tEng\\n', 'Love\\tEng\\n', 'looks\\tEng\\n', 'good\\tEng\\n', 'on\\tEng\\n', 'Maddie\\tEng\\n', '!!!\\tO\\n', 'Ako\\tEng\\n', 'lang\\tEng\\n', 'ba\\tEng\\n', 'yung\\tEng\\n', 'sobrang\\tEng\\n', 'masaya\\tHin\\n', 'kasi\\tHin\\n', 'may\\tHin\\n', 'zolo\\tEng\\n', 'sya\\tEng\\n', '?\\tO\\n', 'Before\\tEng\\n', 'with\\tEng\\n', 'the\\tEng\\n', 'past\\tEng\\n', 'Z\\tHin\\n', 'medyo\\tEng\\n', 'lowkey\\tEng\\n', 's\\tEng\\n', 'â€¦\\tO\\n', '\\n', 'meta\\t12\\tneutral\\n', 'Ye\\tHin\\n', 'Ye\\tHin\\n', '.....\\tO\\n', 'ye\\tHin\\n', '???????\\tO\\n', 'We\\tHin\\n', 'gonna\\tHin\\n', 'start\\tEng\\n', 'another\\tEng\\n', 'June\\tEng\\n', 'on\\tEng\\n', 'a\\tEng\\n', 'sour\\tEng\\n', 'note\\tEng\\n', '?\\tO\\n', 'Uhhhh\\tHin\\n', 'yes\\tHin\\n', 'no\\tEng\\n', 'yes\\tHin\\n', '......\\tO\\n', 'no\\tEng\\n', '(\\tO\\n', 'yes\\tHin\\n', ')\\tO\\n', '\\n', 'meta\\t14\\tneutral\\n', '@\\tO\\n', 'zWffFY9JGklElA1\\tEng\\n', '@\\tO\\n', 'Min\\tEng\\n', '_\\tO\\n', 'Of\\tHin\\n', '_\\tO\\n', 'Lyching\\tEng\\n', '@\\tO\\n', 'thakurdadu089\\tEng\\n', '@\\tO\\n', 'manakgupta\\tEng\\n', '@\\tO\\n', 'OfficeOfKNath\\tHin\\n', 'Mein\\tHin\\n', 'kahna\\tHin\\n', 'nae\\tHin\\n', 'chahta\\tHin\\n', 'qki\\tHin\\n', 'mere\\tHin\\n', 'Yaha\\tHin\\n', 'btay\\tHin\\n', 'â€¦\\tO\\n', 'https\\tEng\\n', '//\\tO\\n', 'tco\\tEng\\n', '/\\tO\\n', 'JWSdvvomt8\\tEng\\n', '\\n', 'meta\\t23\\tnegative\\n', '~\\tO\\n', 'Caring\\tEng\\n', '.\\tO\\n', '~\\tO\\n', 'Bohot\\tHin\\n', 'Jyada\\tHin\\n', 'Caring\\tEng\\n', '.\\tO\\n', '~\\tO\\n', 'Courier\\tEng\\n', 'wale\\tEng\\n', 'bsdk\\tHin\\n']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(l[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=''\n",
    "for i in l:\n",
    "    s=s+i\n",
    "a=s.split('meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\\t12\\tneutral', 'Ye\\tHin', 'Ye\\tHin', '.....\\tO', 'ye\\tHin', '???????\\tO', 'We\\tHin', 'gonna\\tHin', 'start\\tEng', 'another\\tEng', 'June\\tEng', 'on\\tEng', 'a\\tEng', 'sour\\tEng', 'note\\tEng', '?\\tO', 'Uhhhh\\tHin', 'yes\\tHin', 'no\\tEng', 'yes\\tHin', '......\\tO', 'no\\tEng', '(\\tO', 'yes\\tHin', ')\\tO'], ['\\t14\\tneutral', '@\\tO', 'zWffFY9JGklElA1\\tEng', '@\\tO', 'Min\\tEng', '_\\tO', 'Of\\tHin', '_\\tO', 'Lyching\\tEng', '@\\tO', 'thakurdadu089\\tEng', '@\\tO', 'manakgupta\\tEng', '@\\tO', 'OfficeOfKNath\\tHin', 'Mein\\tHin', 'kahna\\tHin', 'nae\\tHin', 'chahta\\tHin', 'qki\\tHin', 'mere\\tHin', 'Yaha\\tHin', 'btay\\tHin', 'â€¦\\tO', 'https\\tEng', '//\\tO', 'tco\\tEng', '/\\tO', 'JWSdvvomt8\\tEng'], ['\\t23\\tnegative', '~\\tO', 'Caring\\tEng', '.\\tO', '~\\tO', 'Bohot\\tHin', 'Jyada\\tHin', 'Caring\\tEng', '.\\tO', '~\\tO', 'Courier\\tEng', 'wale\\tEng', 'bsdk\\tHin', 'ke\\tHin', 'sign\\tHin', 'bhi\\tHin', 'khud\\tHin', 'hi\\tHin', 'krlete\\tHin', 'h\\tHin', 'mera\\tHin', '.\\tO']]\n"
     ]
    }
   ],
   "source": [
    "processed_1=[]\n",
    "for i in range(len(a)):\n",
    "    sen=a[i].split('\\n')\n",
    "    temp=[]\n",
    "    for j in range(len(sen)):\n",
    "        if sen[j]!='':\n",
    "            temp.append(sen[j])\n",
    "    processed_1.append(temp)\n",
    "print(processed_1[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['', '12', 'neutral'], ['Ye', 'Hin'], ['Ye', 'Hin'], ['.....', 'O'], ['ye', 'Hin'], ['???????', 'O'], ['We', 'Hin'], ['gonna', 'Hin'], ['start', 'Eng'], ['another', 'Eng'], ['June', 'Eng'], ['on', 'Eng'], ['a', 'Eng'], ['sour', 'Eng'], ['note', 'Eng'], ['?', 'O'], ['Uhhhh', 'Hin'], ['yes', 'Hin'], ['no', 'Eng'], ['yes', 'Hin'], ['......', 'O'], ['no', 'Eng'], ['(', 'O'], ['yes', 'Hin'], [')', 'O']], [['', '14', 'neutral'], ['@', 'O'], ['zWffFY9JGklElA1', 'Eng'], ['@', 'O'], ['Min', 'Eng'], ['_', 'O'], ['Of', 'Hin'], ['_', 'O'], ['Lyching', 'Eng'], ['@', 'O'], ['thakurdadu089', 'Eng'], ['@', 'O'], ['manakgupta', 'Eng'], ['@', 'O'], ['OfficeOfKNath', 'Hin'], ['Mein', 'Hin'], ['kahna', 'Hin'], ['nae', 'Hin'], ['chahta', 'Hin'], ['qki', 'Hin'], ['mere', 'Hin'], ['Yaha', 'Hin'], ['btay', 'Hin'], ['â€¦', 'O'], ['https', 'Eng'], ['//', 'O'], ['tco', 'Eng'], ['/', 'O'], ['JWSdvvomt8', 'Eng']], [['', '23', 'negative'], ['~', 'O'], ['Caring', 'Eng'], ['.', 'O'], ['~', 'O'], ['Bohot', 'Hin'], ['Jyada', 'Hin'], ['Caring', 'Eng'], ['.', 'O'], ['~', 'O'], ['Courier', 'Eng'], ['wale', 'Eng'], ['bsdk', 'Hin'], ['ke', 'Hin'], ['sign', 'Hin'], ['bhi', 'Hin'], ['khud', 'Hin'], ['hi', 'Hin'], ['krlete', 'Hin'], ['h', 'Hin'], ['mera', 'Hin'], ['.', 'O']], [['', '24', 'positive'], ['@', 'O'], ['AliHZaidiPTI', 'Hin'], ['@', 'O'], ['SarfarazA', 'Hin'], ['_', 'O'], ['54', 'O'], ['What', 'Hin'], ['nonesense', 'Eng'], ['...', 'O'], ['Kabhi', 'Hin'], ['baymani', 'Hin'], ['per', 'Eng'], ['bani', 'Hin'], ['team', 'Eng'], ['kamiyab', 'Hin'], ['nahi', 'Hin'], ['ho', 'Hin'], ['sakti', 'Hin'], ['...', 'O'], ['Jo', 'Hin'], ['log', 'Hin'], ['apnay', 'Hin'], ['liy', 'Hin'], ['â€¦', 'O'], ['https', 'Eng'], ['//', 'O'], ['t', 'Eng'], ['.', 'O'], ['co', 'Eng'], ['/', 'O'], ['al1WFCUTYy', 'Eng']], [['', '26', 'positive'], ['@', 'O'], ['imVkohli', 'Eng'], ['Best', 'Eng'], ['of', 'Eng'], ['luck', 'Eng'], ['@', 'O'], ['imVkohli', 'Hin'], ['sir', 'Hin'], ['World', 'Eng'], ['Cup', 'Hin'], ['ke', 'Hin'], ['liye', 'Hin'], ['bhot', 'Hin'], ['bhot', 'Hin'], ['subhkamnaye', 'Hin']], [['', '27', 'positive'], ['Yes', 'Hin'], ['.', 'O'], ['Great', 'Eng'], ['dialogues', 'Eng'], ['in', 'Eng'], ['that', 'Eng'], ['one', 'Eng'], ['.', 'O'], ['Also', 'Hin'], ['Chupke', 'Hin'], ['Chupke', 'Hin'], ['over', 'Hin'], ['Chhaddabeshi', 'Hin'], ['.', 'O'], ['All', 'Eng'], ['except', 'Eng'], ['R', 'Eng'], ['.', 'O'], ['G', 'Eng'], ['.', 'O'], ['V', 'Eng'], ['.', 'O'], ['Ke', 'Hin'], ['Sholay', 'Hin'], ['-)', 'O'], ['https', 'Eng'], ['//', 'O'], ['t', 'Eng'], ['.', 'O'], ['co', 'Eng'], ['/', 'O'], ['MHCBkX0SnG', 'Eng']], [['', '38', 'negative'], ['@', 'O'], ['mangeshkarlata', 'Hin'], ['Desh', 'Hin'], ['bhakti', 'Hin'], ['baat', 'Hin'], ['wahi', 'Hin'], ['samajh', 'Hin'], ['sakte', 'Hin'], ['hai', 'Hin'], ['jo', 'Hin'], ['khud', 'Hin'], ['deshbhakt', 'Hin'], ['Wo', 'Hin'], ['log', 'Hin'], ['to', 'Hin'], ['sirf', 'Hin'], ['Bharat', 'Hin'], ['tere', 'Hin'], ['tukde', 'Hin'], ['hong', 'Hin'], ['â€¦', 'O'], ['https', 'Eng'], ['//', 'O'], ['t', 'Eng'], ['co', 'Eng'], ['/', 'O'], ['rMdZSiwSGT', 'Eng']], [['', '45', 'positive'], ['Pakistani', 'Eng'], ['team', 'Eng'], ['ne', 'Eng'], ['105', 'O'], ['%', 'O'], ['effort', 'Eng'], ['ki', 'Hin'], ['Aagey', 'Hin'], ['Allah', 'Hin'], ['ki', 'Hin'], ['marziiiiiiiiiiiii', 'Hin'], ['ðŸ˜©ðŸ˜«ðŸ˜–ðŸ˜£\\U0001f97a', 'O'], ['#', 'O'], ['PAKvWI', 'Hin'], ['#', 'O'], ['WIvPAK', 'Eng'], ['#', 'O'], ['CWC19', 'Eng'], ['#', 'O'], ['WeHaveWeWill', 'Eng']], [['', '56', 'negative'], ['@', 'O'], ['Hussain', 'Hin'], ['_', 'O'], ['NSharif', 'Hin'], ['@', 'O'], ['MaryamNSharif', 'Hin'], ['Kiya', 'Hin'], ['tum', 'Hin'], ['apne', 'Hin'], ['baap', 'Hin'], ['ki', 'Hin'], ['oulad', 'Hin'], ['nahi', 'Hin'], ['.??', 'O'], ['Kyun', 'Hin'], ['usy', 'Hin'], ['bay', 'Hin'], ['yaro', 'Hin'], ['madadgar', 'Hin'], ['chora', 'Hin'], ['hua', 'Hin'], ['.', 'O'], ['Kiya', 'Hin'], ['wo', 'Hin'], ['t', 'Eng'], ['â€¦', 'O'], ['https', 'Eng'], ['//', 'O'], ['t', 'Eng'], ['.', 'O'], ['co', 'Eng'], ['/', 'O'], ['E1mrLMGH5c', 'Eng']], [['', '59', 'neutral'], ['@', 'O'], ['TheVijayMallya', 'Hin'], ['@', 'O'], ['YouTube', 'Eng'], ['Are', 'Hin'], ['Tu', 'Hin'], ['aa', 'Hin'], ['rha', 'Hin'], ['h', 'Hin'], ['ki', 'Hin'], ['nhi', 'Hin'], ['Wo', 'Hin'], ['modi', 'Hin'], ['phir', 'Hin'], ['se', 'Hin'], ['PM', 'Eng'], ['ban', 'Eng'], ['gya', 'Hin'], ['Chupchaap', 'Hin'], ['aaja', 'Hin'], ['sidha', 'Hin'], ['sidha', 'Hin'], ['Vrna', 'Hin'], ['mo', 'Eng'], ['â€¦', 'O'], ['https', 'Eng'], ['//', 'O'], ['t', 'Eng'], ['co', 'Hin'], ['/', 'O'], ['iQbN2nsr2S', 'Hin']]]\n"
     ]
    }
   ],
   "source": [
    "processed_2=[]\n",
    "for i in processed_1:\n",
    "    temp=[]\n",
    "    for j in range(len(i)):\n",
    "        temp.append(i[j].split('\\t'))\n",
    "    processed_2.append(temp)\n",
    "print(processed_2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ye', 'Hin']\n"
     ]
    }
   ],
   "source": [
    "processed_3=[]\n",
    "for i in processed_2:\n",
    "    processed_3.append([i[1:],i[0][-1]])\n",
    "print(processed_3[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_4=[]\n",
    "for i in processed_3:\n",
    "    temp=[]\n",
    "    j=0\n",
    "    while j<len(i[0]):\n",
    "        if i[0][j][0]=='@':\n",
    "            j=j+2\n",
    "        elif i[0][j][1]=='O' or i[0][j][1]=='EMT' or i[0][j][0]=='#':\n",
    "            j=j+1\n",
    "        elif len(i[0][j][0])>3 and i[0][j][0][:4]=='http':\n",
    "            break\n",
    "        else:\n",
    "            temp.append(i[0][j])\n",
    "            j=j+1\n",
    "    if temp==[]:\n",
    "        j=0\n",
    "        while j<len(i[0]):\n",
    "            if i[0][j][0]=='@':\n",
    "                j=j+2\n",
    "            elif i[0][j][1]=='O' or i[0][j][1]=='EMT' or i[0][j][0]=='#':\n",
    "                j=j+1\n",
    "            elif len(i[0][j][0])>3 and i[0][j][0][:4]=='http':\n",
    "                while len(i[0][j][0])>1 and (i[0][j][0][-2]+i[0][j][0][-1])!='co':\n",
    "                    j=j+1\n",
    "                j=j+3\n",
    "            else:\n",
    "                temp.append(i[0][j])\n",
    "                j=j+1\n",
    "    if temp==[]:\n",
    "        temp.append(['none','Eng'])\n",
    "    processed_4.append([temp,i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['na88', 'Eng'], ['Loru', 'Eng'], ['singh', 'Hin'], ['tera', 'Hin'], ['bap', 'Hin'], ['jo', 'Hin'], ['brt', 'Eng'], ['peshawer', 'Hin'], ['par', 'Hin'], ['laga', 'Hin'], ['raha', 'Hin'], ['hai', 'Hin'], ['vo', 'Hin'], ['teri', 'Hin'], ['maa', 'Hin'], ['k', 'Hin'], ['phudday', 'Hin'], ['ki', 'Hin'], ['kamayi', 'Hin'], ['hai', 'Hin'], ['ya', 'Hin'], ['baap', 'Hin'], ['ki', 'Hin'], ['gand', 'Hin'], ['ki', 'Hin']], 'negative'], [[['It', 'Eng'], ['means', 'Eng'], ['sidhi', 'Hin'], ['sadhi', 'Hin'], ['ladki', 'Hin'], ['best', 'Eng'], ['couple', 'Eng']], 'positive'], [[['NoTobaccoDay', 'Hin'], ['Tambaku', 'Eng'], ['par', 'Hin'], ['chetavni', 'Hin'], ['likhi', 'Hin'], ['hoti', 'Hin'], ['hai', 'Hin'], ['hi', 'Hin'], ['ki', 'Hin'], ['ise', 'Hin'], ['khane', 'Hin'], ['se', 'Hin'], ['cancer', 'Eng'], ['Hota', 'Hin'], ['Hai', 'Hin'], ['lekin', 'Hin'], ['Sarkar', 'Hin'], ['eyes', 'Hin'], ['band', 'Hin'], ['karane', 'Hin']], 'negative'], [[['RT', 'Hin'], ['The', 'Hin'], ['only', 'Eng'], ['thing', 'Eng'], ['that', 'Eng'], ['i', 'Hin'], ['want', 'Eng'], ['in', 'Eng'], ['my', 'Eng'], ['life', 'Hin'], ['is', 'Eng'], ['to', 'Eng'], ['see', 'Eng'], ['you', 'Eng'], ['happy', 'Eng'], ['and', 'Eng'], ['always', 'Eng'], ['smile', 'Eng'], ['Love', 'Hin'], ['you', 'Hin'], ['to', 'Eng'], ['the', 'Eng'], ['moon', 'Eng'], ['and', 'Eng'], ['back', 'Eng'], ['J', 'Eng'], ['repost', 'Eng'], ['cuz', 'Eng'], ['i', 'Hin']], 'positive'], [[['RT', 'Eng'], ['Bilal', 'Eng'], ['yeh', 'Hin'], ['sab', 'Hin'], ['mujhpr', 'Hin'], ['rely', 'Hin'], ['kar', 'Hin'], ['rahe', 'Hin'], ['hai', 'Hin'], ['D', 'Hin'], ['fahad', 'Hin'], ['Abb', 'Hin'], ['toh', 'Hin'], ['saari', 'Hin'], ['industry', 'Eng'], ['tumpr', 'Hin'], ['rely', 'Hin'], ['karegi', 'Hin'], ['beta', 'Hin'], ['our', 'Hin'], ['boy', 'Eng'], ['making', 'Eng'], ['us', 'Eng']], 'negative'], [[['RT', 'Eng'], ['GRAB', 'Eng'], ['A', 'Hin'], ['COPY', 'Eng'], ['OF', 'Hin'], ['MY', 'Hin'], ['CRITICALLY', 'Eng'], ['ACCLAIMED', 'Eng'], ['BEST', 'Eng'], ['SELLER', 'Eng'], ['HISTORY', 'Eng'], ['OF', 'Hin'], ['THE', 'Hin'], ['DEEP', 'Hin'], ['STATE', 'Hin'], ['Ebook', 'Eng'], ['format', 'Eng'], ['i', 'Eng']], 'positive'], [[['RT', 'Eng'], ['Zeeshan09', 'Eng'], ['Handsome', 'Eng'], ['Hunk', 'Eng'], ['Bhaijaan', 'Hin'], ['Masha', 'Hin'], ['Allah', 'Hin'], ['Zabardast', 'Eng'], ['Fantastic', 'Eng'], ['Mind', 'Eng'], ['Blowing', 'Hin'], ['Awesome', 'Hin'], ['Bhaijan', 'Hin'], ['Bh', 'Hin']], 'positive'], [[['RT', 'Eng'], ['Bin', 'Eng'], ['tere', 'Hin'], ['bin', 'Hin'], ['tere', 'Hin'], ['bin', 'Hin'], ['tere', 'Hin'], ['koi', 'Hin'], ['kharish', 'Hin'], ['h', 'Hin'], ['hawaon', 'Hin'], ['mein', 'Hin'], ['bin', 'Hin'], ['tere', 'Hin'], ['Please', 'Hin'], ['bring', 'Eng'], ['them', 'Eng'], ['back', 'Eng'], ['together', 'Eng']], 'neutral'], [[['Narendra', 'Eng'], ['Modi', 'Hin'], ['Ji', 'Hin'], ['Badhayi', 'Hin'], ['Ho', 'Hin'], ['Varanasi', 'Hin'], ['ka', 'Hin'], ['niwasi', 'Hin'], ['hu', 'Hin'], ['Aur', 'Hin'], ['Hamare', 'Hin'], ['ilake', 'Hin'], ['ka', 'Hin'], ['ek', 'Hin'], ['sadak', 'Hin'], ['Kafi', 'Hin'], ['din', 'Hin'], ['se', 'Hin'], ['nahi', 'Hin'], ['ban', 'Hin'], ['Raha', 'Hin'], ['hai', 'Hin'], ['kr', 'Eng']], 'neutral'], [[['RT', 'Eng'], ['soch', 'Hin'], ['raha', 'Hin'], ['hu', 'Hin'], ['is', 'Hin'], ['baar', 'Hin'], ['uski', 'Hin'], ['birthday', 'Hin'], ['par', 'Eng'], ['gift', 'Eng'], ['me', 'Hin'], ['ek', 'Eng'], ['plastic', 'Eng'], ['ka', 'Hin'], ['dil', 'Hin'], ['de', 'Hin'], ['du', 'Hin'], ['usse', 'Hin'], ['khelti', 'Hin'], ['bhi', 'Hin'], ['rahegi', 'Hin'], ['aur', 'Hin'], ['tootega', 'Hin'], ['bhi', 'Hin'], ['nahi', 'Hin']], 'negative'], [[['aziz', 'Eng'], ['Congress', 'Hin'], ['ne', 'Hin'], ['ye', 'Hin'], ['nirnay', 'Hin'], ['liya', 'Hin'], ['hai', 'Hin'], ['ki', 'Hin'], ['anchor', 'Hin'], ['agar', 'Hin'], ['insaan', 'Hin'], ['ho', 'Hin'], ['to', 'Hin'], ['jae', 'Hin'], ['Bhokne', 'Hin'], ['wale', 'Hin'], ['kutte', 'Hin'], ['ho', 'Hin'], ['jaise', 'Hin'], ['ki', 'Hin'], ['Amish', 'Hin'], ['sad', 'Eng']], 'negative'], [[['Time', 'Hin'], ['main', 'Hin'], ['aya', 'Hin'], ['tha', 'Hin'], ['tm', 'Eng'], ['pubg', 'Hin'], ['khel', 'Hin'], ['ri', 'Hin'], ['the', 'Eng']], 'neutral'], [[['suneel', 'Hin'], ['Poora', 'Hin'], ['khandan', 'Eng'], ['terrorist', 'Eng'], ['hai', 'Hin'], ['aur', 'Hin'], ['ye', 'Hin'], ['khud', 'Hin'], ['khujliwala', 'Hin'], ['kutta', 'Hin'], ['kutto', 'Hin'], ['plz', 'Hin'], ['maaf', 'Hin'], ['karna', 'Hin'], ['tumhari', 'Hin'], ['insult', 'Hin'], ['krne', 'Eng']], 'positive'], [[['Jab', 'Hin'], ['tak', 'Hin'], ['Ramji', 'Hin'], ['k', 'Hin'], ['charno', 'Hin'], ['me', 'Hin'], ['girkar', 'Hin'], ['mangoge', 'Hin'], ['nahi', 'Hin'], ['paoge', 'Hin'], ['nhi', 'Hin'], ['Bhole', 'Hin'], ['baba', 'Hin'], ['ne', 'Hin'], ['hath', 'Hin'], ['khde', 'Hin'], ['kar', 'Hin'], ['liye', 'Hin'], ['Main', 'Hin'], ['unke', 'Hin'], ['khne', 'Hin'], ['pe', 'Hin'], ['nhi', 'Eng']], 'negative'], [[['RT', 'Eng'], ['Soompi', 'Eng'], ['Award', 'Eng'], ['Best', 'Eng'], ['variety', 'Eng'], ['show', 'Eng'], ['Busted', 'Eng'], ['Best', 'Eng'], ['Idol', 'Eng'], ['Actor', 'Hin'], ['Sehun', 'Hin'], ['Best', 'Hin'], ['soundtrack', 'Eng'], ['Live', 'Eng'], ['OST', 'Eng'], ['Best', 'Eng'], ['couple', 'Eng'], ['Kyungsoo', 'Hin'], ['N', 'Hin']], 'negative'], [[['ji', 'Hin'], ['bahut', 'Hin'], ['bahut', 'Hin'], ['subhkamnaye', 'Hin'], ['hope', 'Hin'], ['you', 'Eng'], ['scale', 'Eng'], ['new', 'Eng'], ['heights', 'Eng'], ['in', 'Eng'], ['near', 'Eng'], ['future', 'Eng'], ['CabinetAnnouncement2019', 'Eng']], 'negative'], [[['Rubika', 'Eng'], ['Di', 'Hin'], ['Umar', 'Hin'], ['mein', 'Hin'], ['aap', 'Hin'], ['se', 'Hin'], ['kaafi', 'Hin'], ['chota', 'Hin'], ['hun', 'Hin'], ['Par', 'Hin'], ['I', 'Hin'], ['am', 'Eng'], ['a', 'Eng'], ['big', 'Eng'], ['fan', 'Eng'], ['of', 'Eng'], ['yours', 'Eng'], ['Kabhi', 'Hin'], ['naseeb', 'Hin'], ['ne', 'Hin'], ['chaha', 'Hin'], ['to', 'Hin']], 'neutral'], [[['Yr', 'Eng'], ['k', 'Hin'], ['dor', 'Hin'], ['ka', 'Hin'], ['ek', 'Hin'], ['song', 'Hin'], ['ha', 'Hin'], ['jis', 'Hin'], ['ma', 'Hin'], ['Adnan', 'Hin'], ['Sami', 'Hin'], ['na', 'Hin'], ['Mujahid', 'Eng'], ['k', 'Eng'], ['part', 'Eng'], ['play', 'Eng'], ['keya', 'Hin'], ['tha', 'Hin'], ['Adnan', 'Hin'], ['Sami', 'Hin'], ['ka', 'Hin'], ['wo', 'Hin'], ['song', 'Eng'], ['yad', 'Hin'], ['ha', 'Hin'], ['to', 'Hin'], ['zaror', 'Eng']], 'neutral'], [[['Mp', 'Hin'], ['chunav', 'Hin'], ['me', 'Hin'], ['evm', 'Hin'], ['ne', 'Hin'], ['jitaya', 'Hin'], ['janta', 'Hin'], ['to', 'Eng'], ['Congress', 'Eng'], ['ko', 'Hin'], ['vote', 'Hin'], ['Kiya', 'Hin'], ['tha', 'Hin']], 'neutral'], [[['PhD', 'Eng'], ['You', 'Hin'], ['re', 'Eng'], ['awesome', 'Eng'], ['Much', 'Hin'], ['love', 'Eng'], ['and', 'Eng'], ['hope', 'Eng'], ['to', 'Eng'], ['see', 'Hin'], ['APSA', 'Hin']], 'positive']]\n"
     ]
    }
   ],
   "source": [
    "print(processed_4[30:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:freeze, optimize and export graph, could take a while...\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:optimized graph is stored at: C:\\Users\\Ronak\\AppData\\Local\\Temp\\tmpwuf859bi\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:bind all sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:open 8 ventilator-worker sockets\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:start the sink\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:get devices\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:device map: \n",
      "\t\tworker  0 -> gpu  0\n"
     ]
    }
   ],
   "source": [
    "from bert_serving.server.helper import get_args_parser\n",
    "from bert_serving.server import BertServer\n",
    "args = get_args_parser().parse_args(['-model_dir', 'C:\\\\Users\\\\Ronak\\\\Documents\\\\uncased_L-12_H-768_A-12',\n",
    "                                     '-port', '5555',\n",
    "                                     '-port_out', '5556',\n",
    "                                     '-max_seq_len', '50',\n",
    "                                     '-mask_cls_sep',\n",
    "                                     '-gpu','0.8'])\n",
    "server = BertServer(args)\n",
    "server.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: C:\\Users\\Ronak\\Anaconda3\\envs\\tf-gpu\\Scripts\\bert-serving-terminate -port 5555\n",
      "                 ARG   VALUE\n",
      "__________________________________________________\n",
      "                  ip = localhost\n",
      "                port = 5555\n",
      "             timeout = 5000\n",
      "\n",
      "shutdown signal sent to 5555\n"
     ]
    }
   ],
   "source": [
    "#BertServer.shutdown(port='5555')\n",
    "#bert-serving-terminate -port 5555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:all set, ready to serve request!\n",
      "I:\u001b[35mVENTILATOR\u001b[0m:new config request\treq id: 1\tclient: b'8de763bb-8da7-4fc8-b448-bbcf44154e23'\n"
     ]
    }
   ],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\u001b[35mVENTILATOR\u001b[0m:new encode request\treq id: 2\tsize: 3\tclient: b'8de763bb-8da7-4fc8-b448-bbcf44154e23'\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "o=bc.encode(['First do it', 'then do it right', 'then do it better'])\n",
    "print(type(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_polarity=[]\n",
    "for i in processed_4:\n",
    "    sen=''\n",
    "    print(i)\n",
    "    for j in range(len(i[0])):\n",
    "        sen=sen+' '+i[0][j][0]\n",
    "    embeddings_polarity.append([bc.encode([sen[1:]]),i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(\"embedu\",np.array(embeddings_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, Bidirectional,Flatten,GRU\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import backend as K\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "np_emb_train=np.load(\"embedu.npy\",allow_pickle=1)\n",
    "np_emb_test=np.load(\"test_embedu.npy\",allow_pickle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15114, 2)\n",
      "(1869, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np_emb_train.shape)  \n",
    "print(np_emb_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "m=[]\n",
    "embeddings_polarity=np_emb_train.tolist()\n",
    "for i in range(len(embeddings_polarity)):\n",
    "    l.append(embeddings_polarity[i][0])\n",
    "    if embeddings_polarity[i][1].lower()=='positive':\n",
    "        m.append(1)\n",
    "    elif embeddings_polarity[i][1].lower()=='negative':\n",
    "        m.append(2)\n",
    "    else:\n",
    "        m.append(0)\n",
    "l1=[]\n",
    "m1=[]\n",
    "embeddings_test=np_emb_test.tolist()\n",
    "for i in range(len(embeddings_test)):\n",
    "    l1.append(embeddings_test[i][0])\n",
    "    if embeddings_test[i][1].lower()=='positive':\n",
    "        m1.append(1)\n",
    "    elif embeddings_test[i][1].lower()=='negative':\n",
    "        m1.append(2)\n",
    "    else:\n",
    "        m1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(l)\n",
    "Y_train=np.array(m)\n",
    "Y_train1=np_utils.to_categorical(Y_train)\n",
    "X_test=np.array(l1)\n",
    "Y_test=np.array(m1)\n",
    "Y_test1=np_utils.to_categorical(Y_test)\n",
    "#Y_train=Y_train.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ronak\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ronak\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ronak\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ronak\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ronak\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ronak\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Ronak\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ronak\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "15114/15114 [==============================] - 5s 303us/step - loss: 1.0146 - acc: 0.4622 - f1_m: 0.2371 - precision_m: 0.5448 - recall_m: 0.1571\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.01455, saving model to lstm.hdf5\n",
      "Epoch 2/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.9631 - acc: 0.5090 - f1_m: 0.3704 - precision_m: 0.6013 - recall_m: 0.2704\n",
      "\n",
      "Epoch 00002: loss improved from 1.01455 to 0.96312, saving model to lstm.hdf5\n",
      "Epoch 3/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.9307 - acc: 0.5418 - f1_m: 0.4214 - precision_m: 0.6254 - recall_m: 0.3184\n",
      "\n",
      "Epoch 00003: loss improved from 0.96312 to 0.93068, saving model to lstm.hdf5\n",
      "Epoch 4/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.9158 - acc: 0.5506 - f1_m: 0.4509 - precision_m: 0.6226 - recall_m: 0.3542\n",
      "\n",
      "Epoch 00004: loss improved from 0.93068 to 0.91583, saving model to lstm.hdf5\n",
      "Epoch 5/50\n",
      "15114/15114 [==============================] - 1s 55us/step - loss: 0.9061 - acc: 0.5502 - f1_m: 0.4668 - precision_m: 0.6232 - recall_m: 0.3742\n",
      "\n",
      "Epoch 00005: loss improved from 0.91583 to 0.90607, saving model to lstm.hdf5\n",
      "Epoch 6/50\n",
      "15114/15114 [==============================] - 1s 54us/step - loss: 0.8978 - acc: 0.5627 - f1_m: 0.4808 - precision_m: 0.6330 - recall_m: 0.3886\n",
      "\n",
      "Epoch 00006: loss improved from 0.90607 to 0.89784, saving model to lstm.hdf5\n",
      "Epoch 7/50\n",
      "15114/15114 [==============================] - 1s 50us/step - loss: 0.8833 - acc: 0.5717 - f1_m: 0.4979 - precision_m: 0.6403 - recall_m: 0.4080\n",
      "\n",
      "Epoch 00007: loss improved from 0.89784 to 0.88332, saving model to lstm.hdf5\n",
      "Epoch 8/50\n",
      "15114/15114 [==============================] - 1s 50us/step - loss: 0.8800 - acc: 0.5727 - f1_m: 0.5010 - precision_m: 0.6475 - recall_m: 0.4091\n",
      "\n",
      "Epoch 00008: loss improved from 0.88332 to 0.87998, saving model to lstm.hdf5\n",
      "Epoch 9/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.8673 - acc: 0.5850 - f1_m: 0.5219 - precision_m: 0.6523 - recall_m: 0.4360\n",
      "\n",
      "Epoch 00009: loss improved from 0.87998 to 0.86733, saving model to lstm.hdf5\n",
      "Epoch 10/50\n",
      "15114/15114 [==============================] - 1s 51us/step - loss: 0.8599 - acc: 0.5909 - f1_m: 0.5240 - precision_m: 0.6621 - recall_m: 0.4346\n",
      "\n",
      "Epoch 00010: loss improved from 0.86733 to 0.85987, saving model to lstm.hdf5\n",
      "Epoch 11/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.8476 - acc: 0.5968 - f1_m: 0.5371 - precision_m: 0.6600 - recall_m: 0.4536\n",
      "\n",
      "Epoch 00011: loss improved from 0.85987 to 0.84764, saving model to lstm.hdf5\n",
      "Epoch 12/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.8452 - acc: 0.6010 - f1_m: 0.5444 - precision_m: 0.6624 - recall_m: 0.4628\n",
      "\n",
      "Epoch 00012: loss improved from 0.84764 to 0.84519, saving model to lstm.hdf5\n",
      "Epoch 13/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.8257 - acc: 0.6110 - f1_m: 0.5616 - precision_m: 0.6719 - recall_m: 0.4830\n",
      "\n",
      "Epoch 00013: loss improved from 0.84519 to 0.82573, saving model to lstm.hdf5\n",
      "Epoch 14/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.8239 - acc: 0.6098 - f1_m: 0.5589 - precision_m: 0.6797 - recall_m: 0.4753\n",
      "\n",
      "Epoch 00014: loss improved from 0.82573 to 0.82390, saving model to lstm.hdf5\n",
      "Epoch 15/50\n",
      "15114/15114 [==============================] - 1s 54us/step - loss: 0.8288 - acc: 0.6111 - f1_m: 0.5613 - precision_m: 0.6771 - recall_m: 0.4807\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.82390\n",
      "Epoch 16/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.8128 - acc: 0.6210 - f1_m: 0.5760 - precision_m: 0.6846 - recall_m: 0.4978\n",
      "\n",
      "Epoch 00016: loss improved from 0.82390 to 0.81275, saving model to lstm.hdf5\n",
      "Epoch 17/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.7835 - acc: 0.6371 - f1_m: 0.5981 - precision_m: 0.7019 - recall_m: 0.5215\n",
      "\n",
      "Epoch 00017: loss improved from 0.81275 to 0.78346, saving model to lstm.hdf5\n",
      "Epoch 18/50\n",
      "15114/15114 [==============================] - 1s 55us/step - loss: 0.7695 - acc: 0.6442 - f1_m: 0.6102 - precision_m: 0.7049 - recall_m: 0.5383\n",
      "\n",
      "Epoch 00018: loss improved from 0.78346 to 0.76954, saving model to lstm.hdf5\n",
      "Epoch 19/50\n",
      "15114/15114 [==============================] - 1s 55us/step - loss: 0.7697 - acc: 0.6417 - f1_m: 0.6076 - precision_m: 0.7010 - recall_m: 0.5368\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.76954\n",
      "Epoch 20/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.7452 - acc: 0.6544 - f1_m: 0.6245 - precision_m: 0.7139 - recall_m: 0.5554\n",
      "\n",
      "Epoch 00020: loss improved from 0.76954 to 0.74523, saving model to lstm.hdf5\n",
      "Epoch 21/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.7314 - acc: 0.6661 - f1_m: 0.6391 - precision_m: 0.7242 - recall_m: 0.5725\n",
      "\n",
      "Epoch 00021: loss improved from 0.74523 to 0.73144, saving model to lstm.hdf5\n",
      "Epoch 22/50\n",
      "15114/15114 [==============================] - 1s 51us/step - loss: 0.7190 - acc: 0.6780 - f1_m: 0.6509 - precision_m: 0.7316 - recall_m: 0.5867\n",
      "\n",
      "Epoch 00022: loss improved from 0.73144 to 0.71898, saving model to lstm.hdf5\n",
      "Epoch 23/50\n",
      "15114/15114 [==============================] - 1s 51us/step - loss: 0.6965 - acc: 0.6860 - f1_m: 0.6621 - precision_m: 0.7408 - recall_m: 0.5988\n",
      "\n",
      "Epoch 00023: loss improved from 0.71898 to 0.69653, saving model to lstm.hdf5\n",
      "Epoch 24/50\n",
      "15114/15114 [==============================] - 1s 55us/step - loss: 0.6839 - acc: 0.6947 - f1_m: 0.6720 - precision_m: 0.7480 - recall_m: 0.6104\n",
      "\n",
      "Epoch 00024: loss improved from 0.69653 to 0.68386, saving model to lstm.hdf5\n",
      "Epoch 25/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.6763 - acc: 0.7012 - f1_m: 0.6785 - precision_m: 0.7546 - recall_m: 0.6170\n",
      "\n",
      "Epoch 00025: loss improved from 0.68386 to 0.67625, saving model to lstm.hdf5\n",
      "Epoch 26/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.6525 - acc: 0.7107 - f1_m: 0.6920 - precision_m: 0.7628 - recall_m: 0.6338\n",
      "\n",
      "Epoch 00026: loss improved from 0.67625 to 0.65247, saving model to lstm.hdf5\n",
      "Epoch 27/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.6365 - acc: 0.7181 - f1_m: 0.7023 - precision_m: 0.7675 - recall_m: 0.6477\n",
      "\n",
      "Epoch 00027: loss improved from 0.65247 to 0.63652, saving model to lstm.hdf5\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.6273 - acc: 0.7231 - f1_m: 0.7039 - precision_m: 0.7745 - recall_m: 0.6457\n",
      "\n",
      "Epoch 00028: loss improved from 0.63652 to 0.62728, saving model to lstm.hdf5\n",
      "Epoch 29/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.6235 - acc: 0.7250 - f1_m: 0.7110 - precision_m: 0.7768 - recall_m: 0.6559\n",
      "\n",
      "Epoch 00029: loss improved from 0.62728 to 0.62350, saving model to lstm.hdf5\n",
      "Epoch 30/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.5760 - acc: 0.7486 - f1_m: 0.7404 - precision_m: 0.7953 - recall_m: 0.6928\n",
      "\n",
      "Epoch 00030: loss improved from 0.62350 to 0.57596, saving model to lstm.hdf5\n",
      "Epoch 31/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.5741 - acc: 0.7525 - f1_m: 0.7400 - precision_m: 0.7936 - recall_m: 0.6936\n",
      "\n",
      "Epoch 00031: loss improved from 0.57596 to 0.57405, saving model to lstm.hdf5\n",
      "Epoch 32/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.5563 - acc: 0.7573 - f1_m: 0.7490 - precision_m: 0.8002 - recall_m: 0.7043\n",
      "\n",
      "Epoch 00032: loss improved from 0.57405 to 0.55629, saving model to lstm.hdf5\n",
      "Epoch 33/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.5593 - acc: 0.7544 - f1_m: 0.7431 - precision_m: 0.7967 - recall_m: 0.6966\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.55629\n",
      "Epoch 34/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.5219 - acc: 0.7767 - f1_m: 0.7697 - precision_m: 0.8165 - recall_m: 0.7283\n",
      "\n",
      "Epoch 00034: loss improved from 0.55629 to 0.52190, saving model to lstm.hdf5\n",
      "Epoch 35/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.5089 - acc: 0.7815 - f1_m: 0.7752 - precision_m: 0.8217 - recall_m: 0.7340\n",
      "\n",
      "Epoch 00035: loss improved from 0.52190 to 0.50885, saving model to lstm.hdf5\n",
      "Epoch 36/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.5184 - acc: 0.7735 - f1_m: 0.7646 - precision_m: 0.8127 - recall_m: 0.7222\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.50885\n",
      "Epoch 37/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.4734 - acc: 0.7994 - f1_m: 0.7931 - precision_m: 0.8313 - recall_m: 0.7584\n",
      "\n",
      "Epoch 00037: loss improved from 0.50885 to 0.47339, saving model to lstm.hdf5\n",
      "Epoch 38/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.4681 - acc: 0.8040 - f1_m: 0.7992 - precision_m: 0.8379 - recall_m: 0.7640\n",
      "\n",
      "Epoch 00038: loss improved from 0.47339 to 0.46807, saving model to lstm.hdf5\n",
      "Epoch 39/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.4796 - acc: 0.7971 - f1_m: 0.7904 - precision_m: 0.8283 - recall_m: 0.7559\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.46807\n",
      "Epoch 40/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.4756 - acc: 0.7977 - f1_m: 0.7899 - precision_m: 0.8313 - recall_m: 0.7526\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.46807\n",
      "Epoch 41/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.4646 - acc: 0.8033 - f1_m: 0.7980 - precision_m: 0.8366 - recall_m: 0.7631\n",
      "\n",
      "Epoch 00041: loss improved from 0.46807 to 0.46456, saving model to lstm.hdf5\n",
      "Epoch 42/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.4195 - acc: 0.8227 - f1_m: 0.8188 - precision_m: 0.8490 - recall_m: 0.7909\n",
      "\n",
      "Epoch 00042: loss improved from 0.46456 to 0.41952, saving model to lstm.hdf5\n",
      "Epoch 43/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.4059 - acc: 0.8284 - f1_m: 0.8253 - precision_m: 0.8552 - recall_m: 0.7975: 0s - loss: 0.4459 - acc: 0.8055 - f1_m: 0.8027 - precision_m: 0.8281 - re\n",
      "\n",
      "Epoch 00043: loss improved from 0.41952 to 0.40589, saving model to lstm.hdf5\n",
      "Epoch 44/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.4472 - acc: 0.8135 - f1_m: 0.8089 - precision_m: 0.8438 - recall_m: 0.7771\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.40589\n",
      "Epoch 45/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.4248 - acc: 0.8195 - f1_m: 0.8169 - precision_m: 0.8472 - recall_m: 0.7889\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.40589\n",
      "Epoch 46/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.3930 - acc: 0.8353 - f1_m: 0.8326 - precision_m: 0.8604 - recall_m: 0.8067\n",
      "\n",
      "Epoch 00046: loss improved from 0.40589 to 0.39300, saving model to lstm.hdf5\n",
      "Epoch 47/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.3969 - acc: 0.8311 - f1_m: 0.8307 - precision_m: 0.8567 - recall_m: 0.8063\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.39300\n",
      "Epoch 48/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.3849 - acc: 0.8404 - f1_m: 0.8367 - precision_m: 0.8649 - recall_m: 0.8104\n",
      "\n",
      "Epoch 00048: loss improved from 0.39300 to 0.38486, saving model to lstm.hdf5\n",
      "Epoch 49/50\n",
      "15114/15114 [==============================] - 1s 53us/step - loss: 0.3854 - acc: 0.8388 - f1_m: 0.8372 - precision_m: 0.8662 - recall_m: 0.8103\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.38486\n",
      "Epoch 50/50\n",
      "15114/15114 [==============================] - 1s 52us/step - loss: 0.3554 - acc: 0.8542 - f1_m: 0.8532 - precision_m: 0.8771 - recall_m: 0.8307\n",
      "\n",
      "Epoch 00050: loss improved from 0.38486 to 0.35538, saving model to lstm.hdf5\n"
     ]
    }
   ],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def LSTM_model():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128,input_shape=(1,768),return_sequences=1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(SeqSelfAttention(attention_width=15,attention_activation='sigmoid'))\n",
    "    #model.add(Dense(3, activation='softmax'))\n",
    "    model.add(GRU(20))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(100,return_sequences=1))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(200))\n",
    "#     model.add(Dropout(0.2))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    #print(model.summary())\n",
    "    filepath=\"lstm.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model.fit(X_train, Y_train1, epochs=50, batch_size=256,callbacks=callbacks_list)\n",
    "    return model\n",
    "model=LSTM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, Y_test1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47458533991333507, 0.4636841165375237, 0.47930585588600116)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, f1_score, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  negative  neutral  positive\n",
      "Actual                                \n",
      "negative        323      207       224\n",
      "neutral         193      279       110\n",
      "positive        172       76       285\n",
      "\n",
      "\n",
      "Accuracy:  0.47458533975387907\n",
      "\n",
      " Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.43      0.45       754\n",
      "     neutral       0.50      0.48      0.49       582\n",
      "    positive       0.46      0.53      0.49       533\n",
      "\n",
      "    accuracy                           0.47      1869\n",
      "   macro avg       0.48      0.48      0.48      1869\n",
      "weighted avg       0.48      0.47      0.47      1869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_dct = {'negative':0, \"neutral\":1,\"positive\":2}\n",
    "y_test_int = []\n",
    "for i in range(len(Y_test)):\n",
    "      y_test_int.append(Y_test[i])\n",
    "from sklearn.metrics import classification_report as clf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "y_pred=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    y_pred.append(np.argmax(model.predict(np.array([X_test[i]]))))\n",
    "target_names=['negative','neutral','positive']\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(Y_test, y_pred), columns=target_names, index=target_names)\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "print(df_cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy: \",accuracy_score(Y_test, y_pred))\n",
    "print(\"\\n\",\"Report:\")\n",
    "print(clf(Y_test, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
